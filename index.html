

<meta name="description" content="Tianyu's homepage">
<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
<title>Tianyu Pang's Homepage</title>


<body>

<div id="layout-content" style="margin-top:25px">

<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Tianyu Pang &nbsp;</div>

				<h3>Ph.D. Candidate</h3>  
				<p>
					Room 1-509, FIT Building <br>
					Dept. of Computer Science and Technology<br>
					Tsinghua University <br>
					Beijing, China, 100084.<br>
					<br>
Email:  <a href="mailto:pty17@mails.tsinghua.edu.cn">pty17@mails.tsinghua.edu.cn</a>; <a href="mailto:tianyupang3@gmail.com">tianyupang3@gmail.com</a> <br>
Github: <a href="https://github.com/P2333">P2333</a> <br>
<br>
<a href="https://scholar.google.com/citations?hl=zh-CN&user=wYDbtFsAAAAJ&view_op=list_works&gmla=AJsN-F6tkfVfHMXfMT4-eIK87hw8g9mdPc8d9hlVPXfJpCPW_lYPCY8YLGKVs-S5ReZf26m7dBv5q82uIDtjthGWC9WFor68N-gQz0DTHKaMJr_8fUq9EMc">[Google Scholar]</a> <a href="https://twitter.com/TianyuPang1">[Twitter]</a> 
					<br>
				</p>
			</td>
			<td>
				<img src="./files/tianyu4.jpg" border="0" width="200">
			</td>
		</tr><tr>
	</tr></tbody>
</table>
<h2>Biography</h2>
<p>
	I am a final-year bachelor-straight-to-PhD student of <a href="http://ml.cs.tsinghua.edu.cn/index.html">TSAIL Group</a> in the <a href="http://www.cs.tsinghua.edu.cn/en/">Department of Computer Science and Technology</a>, <a href="http://www.tsinghua.edu.cn/publish/then/index.html">Tsinghua University</a>, advised by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a>. Before that, I received my B.S. degree of <a href="http://www.phys.tsinghua.edu.cn/">Mathematics and Physics</a> in 2017.
    </p>

    <p>Recently I am a research intern at Sea AI Lab, advised by <a href="https://scholar.google.com/citations?hl=en&user=BGONmkIAAAAJ">Min Lin</a>. I was a research intern from August, 2019 to Novemeber, 2019 (advised by <a href="https://www.linkedin.com/in/yujing-kelly-wang-b91b3560/?originalSubdomain=cn">Yujing Wang</a>) and from July, 2020 to February, 2021 (advised by <a href="https://scholar.google.com/citations?hl=zh-CN&user=w1srHyIAAAAJ">Huishuai Zhang</a>) at Microsoft Research Asia. I collaborated with <a href="https://cs.stanford.edu/~ermon/">Prof. Stefano Ermon</a> from February, 2020 to June, 2020 (online) in the Computer Science Department, Stanford University. I was a visiting student from July, 2016 to September, 2016 in the Computational Biology Department, Carnegie Mellon University, advised by <a href="http://www.cs.cmu.edu/~weiwu2/">Prof. Wei Wu</a>.</p>
    <!-- I was a research intern under the NVAIL program of <a href="https://www.nvidia.com/en-us/">NVIDIA</a> from November, 2018 to September, 2020. -->
	
	<p>My research interests span the areas of machine learning and deep learning, including adversarial robustness, deep generative models, and representation learning. My research is supported by <a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/#!fellows">MSRA Fellowship</a> and <a href="http://scholarship.baidu.com">Baidu Scholarship</a>.</p>

	<p><a href='https://github.com/P2333/Papers-of-Robust-ML/blob/master/README.md'><font color="#FF8C00">Paper reading list of recent research on Robust ML</font></a></p>

    <p><a href='https://github.com/P2333/Bag-of-Tricks-for-AT'><font color="#FF8C00">Bag of tricks for adversarial training</font></a></p>




<h2>Publications</h2>
<ul>
    <li>
         <a href='https://arxiv.org/abs/2106.09993'>Accumulative Poisoning Attacks on Real-time Data</a> <br>
         <strong><u>Tianyu Pang</u>*</strong>, Xiao Yang*, Yinpeng Dong, Hang Su, Jun Zhu<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Online, 2021 <br>
         <a href="https://github.com/ShawnXYang/AccumulativeAttack">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/accumulative/accumulative.pdf">[slide]</a>
         <a href="https://arxiv.org/abs/2106.09993">[appendix]</a>
    </li>
    <li>
         <a href='https://arxiv.org/abs/2003.06814'>Towards Privacy Protection by Generating Adversarial Identity Masks</a> <br>
         Xiao Yang, Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Jun Zhu, Hang Su<br>
         International Conference on Computer Vision <strong>(ICCV)</strong>, Online, 2021<br>
    </li>
    <li>
         <a href='https://arxiv.org/abs/2103.13127'>Black-box Detection of Backdoor Attacks with Limited Information and Data</a> <br>
         Yinpeng Dong, Xiao Yang, Zhijie Deng, <strong><u>Tianyu Pang</u></strong>, Zihao Xiao, Hang Su, and Jun Zhu<br>
         International Conference on Computer Vision <strong>(ICCV)</strong>, Online, 2021<br>
    </li>
    <li>
         <a href='https://openreview.net/forum?id=Xb8xvrtB8Ce'>Bag of Tricks for Adversarial Training</a> <br>
         <strong><u>Tianyu Pang</u></strong>, Xiao Yang, Yinpeng Dong, Hang Su, Jun Zhu<br>
         International Conference on Learning Representations <strong>(ICLR)</strong>, Online, 2021 <br>
         <a href="https://github.com/P2333/Bag-of-Tricks-for-AT">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/bag_of_tricks/BagOfTricks_poster.pdf">[poster]</a>
         <a href="https://arxiv.org/pdf/2010.00467.pdf">[appendix]</a>
    </li>
    <li>
         <a href='http://ml.cs.tsinghua.edu.cn/~tianyu/'>Query-Efficient Black-box Adversarial Attacks Guided by a Transfer-based Prior</a> <br>
         Yinpeng Dong, Shuyu Cheng, <strong><u>Tianyu Pang</u></strong>, Hang Su, and Jun Zhu<br>
         IEEE Transaction on Pattern Analysis and Machine Intelligence <strong>(TPAMI)</strong>, under minor revision, 2021 <br>
    </li>
    <li>
         <a href='https://arxiv.org/pdf/2007.03317.pdf'>Efficient Learning of Generative Models via Finite-Difference Score Matching</a> <br>
         <strong><u>Tianyu Pang</u>*</strong>, Kun Xu*, Chongxuan Li, Yang Song, Stefano Ermon, Jun Zhu<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Online, 2020 <br>
         <a href="https://github.com/taufikxu/FD-ScoreMatching">[code]</a>
         <a href="https://nips.cc/virtual/2020/protected/poster_de6b1cf3fb0a3aa1244d30f7b8c29c41.html">[video]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/FDSM/FD-Poster.pdf">[poster]</a>
         <a href="https://arxiv.org/pdf/2007.03317.pdf">[appendix]</a>
    </li>
    <li>
         <a href='https://arxiv.org/pdf/2002.08619.pdf'>Boosting Adversarial Training with Hypersphere Embedding</a> <br>
         <strong><u>Tianyu Pang</u>*</strong>, Xiao Yang*, Yinpeng Dong, Kun Xu, Jun Zhu, Hang Su<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Online, 2020 <br>
         <a href="https://github.com/ShawnXYang/AT_HE">[code]</a>
         <a href="https://nips.cc/virtual/2020/protected/poster_5898d8095428ee310bf7fa3da1864ff7.html">[video]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/ATHE/ATHE_poster.pdf">[poster]</a>
         <a href="https://arxiv.org/pdf/2002.08619.pdf">[appendix]</a>
    </li>
    <li>
         <a href='https://arxiv.org/pdf/2002.05999.pdf'>Adversarial Distributional Training for Robust Deep Learning</a> <br>
         Zhijie Deng, Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Hang Su, Jun Zhu<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Online, 2020 <br>
    </li>
	<li>
         <a href='http://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_Benchmarking_Adversarial_Robustness_on_Image_Classification_CVPR_2020_paper.pdf'>Benchmarking Adversarial Robustness on Image Classification</a> (<font color="#FF0000"><strong>Oral</strong></font>) <br>
         Yinpeng Dong, Qi-An Fu, Xiao Yang, <strong><u>Tianyu Pang</u></strong>, Hang Su, Zihao Xiao, Jun Zhu<br>
         IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Online, 2020 <br>
         <a href="https://github.com/thu-ml/realsafe">[platform]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~yinpeng/slides/CVPR2020-5414.pdf">[slide]</a>
	</li>
	<li>
         <a href='https://openreview.net/forum?id=Byg9A24tvB&noteId=Byg9A24tvB'>Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness</a> <br>
         <strong><u>Tianyu Pang</u></strong>, Kun Xu, Yinpeng Dong, Chao Du, Ning Chen, Jun Zhu<br>
         International Conference on Learning Representations <strong>(ICLR)</strong>, Online, 2020 <br>
         <a href="https://github.com/P2333/Max-Mahalanobis-Training">[code]</a>
         <a href="https://iclr.cc/virtual/poster_Byg9A24tvB.html">[video]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/MMC/MMC.pdf">[slide]</a>
         <a href="https://arxiv.org/pdf/1905.10626.pdf">[appendix]</a>
	</li>
	<li>
         <a href='https://openreview.net/forum?id=ByxtC2VtPB&noteId=ByxtC2VtPB'>Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks</a> <br>
         <strong><u>Tianyu Pang</u>*</strong>, Kun Xu*, Jun Zhu<br>
         International Conference on Learning Representations <strong>(ICLR)</strong>, Online, 2020 <br>
         <a href="https://github.com/P2333/Mixup-Inference">[code]</a>
         <a href="https://iclr.cc/virtual/poster_ByxtC2VtPB.html">[video]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/MixupInference/MI.pdf">[slide]</a>
         <a href="https://arxiv.org/pdf/1909.11515.pdf">[appendix]</a>
	</li>
	<li>
         <a href='https://arxiv.org/pdf/1906.06919.pdf'>Improving Black-box Adversarial Attacks with a Transfer-based Prior</a> <br>
         Shuyu Cheng, Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Hang Su, Jun Zhu<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Vancouver, Canada, 2019 <br>
	</li>
	<li>
         <a href='http://proceedings.mlr.press/v97/pang19a/pang19a.pdf'>Improving Adversarial Robustness via Promoting Ensemble Diversity</a> <br>
         <strong><u>Tianyu Pang</u></strong>, Kun Xu, Chao Du, Ning Chen, Jun Zhu<br>
         International Conference on Machine Learning <strong>(ICML)</strong>, Long Beach, USA, 2019 <br>
         <a href="https://github.com/P2333/Adaptive-Diversity-Promoting">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/ADP/ADP-poster.pdf">[poster]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/ADP/ADP.pdf">[slide]</a>
         <a href="https://arxiv.org/pdf/1901.08846.pdf">[appendix]</a>
	</li>
		<li>
         <a href='https://arxiv.org/pdf/1904.02884.pdf'>Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks</a> (<font color="#FF0000"><strong>Oral</strong></font>) <br>
         Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Hang Su, Jun Zhu<br>
         IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Long Beach, USA, 2019 <br>
         <a href="https://github.com/dongyp13/Translation-Invariant-Attacks">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~yinpeng/papers/CVPR2019-5297.mp4">[video]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~yinpeng/poster/CVPR2019-5297.pdf">[poster]</a>
	</li>	
	    <li>
         <a href='http://papers.nips.cc/paper/7709-towards-robust-detection-of-adversarial-examples.pdf'>Towards Robust Detection of Adversarial Examples</a> (<font color="#FF0000"><strong>Spotlight</strong></font>) <br>
         <strong><u>Tianyu Pang</u></strong>, Chao Du, Yinpeng Dong, Jun Zhu<br>
         Annual Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, Montreal, Canada, 2018 <br>
         <a href="https://github.com/P2333/Reverse-Cross-Entropy">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/RCE/RCE_poster.pdf">[poster]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/RCE/RCE.pdf">[slide]</a>
         <a href="https://arxiv.org/pdf/1706.00633.pdf">[appendix]</a>
         <a href="https://www.videoken.com/embed/BpZexDgwDHM?tocitem=76">[video]</a>
         <a href="https://www.forbes.com/sites/nvidia/2018/12/26/deep-learning-innovation-starts-in-the-lab/#4f50975a5d7d">[press release]</a>	
    </li>	
		<li>
         <a href='http://proceedings.mlr.press/v80/pang18a/pang18a.pdf'>Max-Mahalanobis Linear Discriminant Analysis Networks</a> <br>
         <strong><u>Tianyu Pang</u></strong>, Chao Du, Jun Zhu<br>
         International Conference on Machine Learning <strong>(ICML)</strong>, Stockholm, Sweden, 2018 <br>
         <a href="https://github.com/P2333/Max-Mahalanobis-Training">[code]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/MMLDA/mmlda-poster.pdf">[poster]</a>
         <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/MMLDA/MMLDA.pdf">[slide]</a>
         <a href="https://arxiv.org/pdf/1802.09308.pdf">[appendix]</a>
	</li>
		<li>
         <a href='https://arxiv.org/pdf/1712.02976.pdf'>Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser</a> <br>
         Fangzhou Liao, Ming Liang, Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Jun Zhu, Xiaolin Hu<br>
         IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Salt Lake City, USA, 2018 <br>
	</li>
		<li>
         <a href='https://arxiv.org/pdf/1710.06081.pdf'>Boosting Adversarial Attacks with Momentum</a> (<font color="#FF0000"><strong>Spotlight</strong></font>) <br>
         Yinpeng Dong, Fangzhou Liao, <strong><u>Tianyu Pang</u></strong>, Hang Su, Xiaolin Hu, Jianguo Li, Jun Zhu<br>
         IEEE Conference on Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, Salt Lake City, USA, 2018 <br>
	</li>		
</ul>

<!-- <h2>Workshops</h2>
<ul>
	<li>
         <a href='http://gimli.cc/2018/public_abstracts/gimli2018_zou_et_al.pdf'>Geometric Universality of Adversarial Examples in Deep Learning</a> <br>
         Haosheng Zou, Hang Su, <strong><u>Tianyu Pang</u></strong>, Jun Zhu<br>
         ICML Workshop on Geometry in Machine Learning, Stockholm, Sweden, 2018 <br>
	</li>
	<li>
         <a href='https://arxiv.org/pdf/1804.00097.pdf'>Adversarial Attacks and Defences Competition</a> <br>
         Alexey Kurakin, Ian Goodfellow, Samy Bengio, Yinpeng Dong, Fangzhou Liao, Ming Liang, <strong><u>Tianyu Pang</u></strong>, Jun Zhu, Xiaolin Hu, Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, Alan Yuille, et al. <br>
         NeurIPS 2017 Competition Chapter <br>
	</li>		
</ul> -->

<!-- <h2>Preprints and under review</h2>
<ul>
    <li>
         <a href='https://arxiv.org/abs/2105.14785'>Adversarial Training with Rectified Rejection</a> <br>
         <strong><u>Tianyu Pang</u></strong>, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen, Jun Zhu, Tie-Yan Liu<br>
         arXiv preprint 2105.14785<br>
         <a href="https://github.com/P2333/Rectified-Rejection">[code]</a>
         <a href="https://arxiv.org/abs/2105.14785">[appendix]</a>
    </li>
    <li>
         <a href='https://arxiv.org/abs/2107.01809'>Boosting Transferability of Targeted Adversarial Examples via Hierarchical Generative Networks</a> <br>
         Xiao Yang, Yinpeng Dong, <strong><u>Tianyu Pang</u></strong>, Hang Su, Jun Zhu<br>
         arXiv preprint 2107.01809<br>
    </li>
    <li>
         <a href='https://arxiv.org/abs/2106.01606'>Exploring Memorization in Adversarial Training</a> <br>
         Yinpeng Dong, Ke Xu, Xiao Yang, <strong><u>Tianyu Pang</u></strong>, Zhijie Deng, Hang Su, Jun Zhu<br>
         arXiv preprint 2106.01606<br>
    </li>       
</ul> -->


<h2>Honors &amp; Awards</h2>
<ul>
    <li>
        <strong>Baidu Scholarship</strong>, 2020.12
    </li>
    <li>
        <strong>Zhong Shimo Scholarship</strong>, 2020.11
    </li>
    <li>
        <strong>Microsoft Research Asia (MSRA) Fellowship</strong>, 2020.11
    </li>
    <li>
        <strong>Shenzhen Stock Exchange Scholarship</strong>, 2020.10
    </li>
	<li>
		<strong>'84' Future Innovation Scholarship</strong>, 2019.12
	</li>
	<li>
		<strong>China National Scholarship</strong>, 2019.10
	</li>
	<!-- <li>
		<strong>Google AI ML Winter Camp Best Presentation Project</strong>, 2019.01
	</li> -->
	<li>
		<strong>NVIDIA Pioneering Research Award</strong>, 2018.12
	</li>
	<li>
		<strong>Schlumberger Scholarship</strong>, 2018.10
	</li>
	<!-- <li>
		<strong>Tsinghua Physical Fund for Summer Research</strong>, 2016.07
	</li> -->
	<!-- <li>
		<strong>Bronze Medal of 28th Chinese Physics Olympiad (CPhO)</strong>, 2011.11
	</li> -->
</ul>


<h2>Competitions</h2>

<ul>
    <li>
        2020.10 -- <br>
        <strong>Inclusion | A-tech Contest:</strong> <br> 
        <a href="https://www.bilibili.com/video/BV1xr4y1T7Mx?from=search&seid=2418129539771656515">Part One</a>, <a href="https://www.bilibili.com/video/BV1q5411n76v?from=search&seid=2418129539771656515">Part Two</a>, 1st place of AI track <br>
       </li>
	<li>
       	2018.8 -- <br>
       	<strong>GeekPwn 2018 The Worldwide Cyber Security Contest:</strong> <br> 
       	<a href="http://hof.geekpwn.org/caad/zh/index2.html">CAAD CTF Las Vegas</a>, 1st place <br>
       	<a href="http://hof.geekpwn.org/caad/zh/index3.html">CAAD CTF Shanghai</a>, 3rd place <br>
       	<a href="http://hof.geekpwn.org/caad/zh/index.html">CAAD Non-targeted Adversarial Attacks Track</a>, 3rd place <br>
       	<a href="http://hof.geekpwn.org/caad/zh/index.html">CAAD Targeted Adversarial Attacks Track</a>, 2nd place <br>
       	<a href="http://hof.geekpwn.org/caad/zh/index.html">CAAD Defense Against Adversarial Attack Track</a>, 2nd place
       </li>
	<li>
       	2017.10 -- <br>
       	<strong>NeurIPS 2017 Adversarial Attacks and Defense Competition:</strong> <br>
       	<a href="https://www.kaggle.com/c/nips-2017-non-targeted-adversarial-attack/">Non-targeted Adversarial Attacks Track</a>, 1st place <br>
       	<a href="https://www.kaggle.com/c/nips-2017-targeted-adversarial-attack/">Targeted Adversarial Attacks</a>, 1st place <br>
       	<a href="https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack">Defense Against Adversarial Attack</a>, 1st place
       </li>
</ul>

<h2>Services</h2>

I was an organizer of: <br>
<strong>AAAI 2022 Workshop</strong> (Adversarial Machine Learning and Beyond) <a href="https://advml-workshop.github.io/aaai2022/">[link]</a><br>
<strong>ICML 2021 Workshop</strong> (A Blessing in Disguise: The Prospects and Perils of Adversarial Machine Learning) <a href="https://advml-workshop.github.io/icml2021/">[link]</a><br>
<strong>ICCV 2021 Workshop</strong> (Adversarial Robustness in the Real World) <a href="https://iccv21-adv-workshop.github.io/">[link]</a><br>
<br>

I was a reviewer / PC member of conferences: <br>
<strong>ICML 2019, 2020, 2021</strong> <br>
<strong>ICLR 2020, 2021, 2022</strong> <br>
<strong>NeurIPS 2019, 2020, 2021</strong> <br>
<strong>AISTATS 2020, 2022</strong> <br>
<strong>CVPR 2019, 2020, 2021, 2022</strong> <br>
<strong>ICCV 2019, 2021</strong> <br>
<strong>ECCV 2020</strong> <br>
<strong>AAAI 2020</strong> <br>
<br>

I was a reviewer of journals: <br>
<strong>TPAMI, IJCV, TNNLS, TKDD, T-IFS, Neurocomputing</strong> <br>
	

<h2>Invited Talks</h2>
<ul>
    <li>
        <strong>Alibaba Security, BiliBili</strong>, 2021.3 <a href="https://www.bilibili.com/video/BV1uA411N7i9">[video]</a><a href="http://ml.cs.tsinghua.edu.cn/~tianyu/talks/tianyupang_AlibabaSecurity.pdf">[slide]</a>
    </li>
    <li>
        <strong>VALSE Webinar, BiliBili</strong>, 2020.12 <a href="https://www.bilibili.com/video/BV1iK4y1V7q9">[video]</a><a href="http://ml.cs.tsinghua.edu.cn/~tianyu/talks/tianyupang_VALSE.pdf">[slide]</a>
    </li>
    <li>
        <strong>RealCourse, RealAI</strong>, 2020.5 <a href="https://www.bilibili.com/video/BV1xk4y167Rw?from=search&seid=12790299826686879371">[video]</a><a href="http://ml.cs.tsinghua.edu.cn/~tianyu/talks/tianyupang_realcourse.pdf">[slide]</a>
    </li>
    <li>
        <strong>CAAD CTF, DEFCON</strong>, 2018.8 <a href="http://ml.cs.tsinghua.edu.cn/~tianyu/talks/tianyupang_CAADCTF.pdf">[slide]</a>
    </li>
</ul>


<h2>Teaching</h2>
<p>
2019 Fall, TA in <strong>Machine Learning</strong>, instructed by Prof. Jun Zhu


<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2021 Tianyu Pang
</body></html>
